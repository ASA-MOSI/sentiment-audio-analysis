{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries and Define constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\THEDE\\Miniconda3\\envs\\py36\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "C:\\Users\\THEDE\\Miniconda3\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#### Training based on features of audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sknn.mlp import Classifier, Layer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots_adjust\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size input, output, transcripts:  10018 ,  10018 , 10018\n"
     ]
    }
   ],
   "source": [
    "##Loading  data from files\n",
    "filehandlerInput = open('processed-data/input_VAD.obj', 'rb')\n",
    "filehandlerOutput = open('processed-data/output_VAD.obj', 'rb')\n",
    "filehandlerTranscript = open('processed-data/transcript_VAD.obj', 'rb')\n",
    "input = pickle.load(filehandlerInput)\n",
    "output = pickle.load(filehandlerOutput)\n",
    "texts = pickle.load(filehandlerTranscript)\n",
    "print(\"Size input, output, transcripts: \", len(input),\", \", len(output), \",\", len(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess data and Analyze data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct output:  {0.5, 1.5, 2.5, 3.5, 3.0, 4.0, 2.0, 4.5, 5.0, 1.0, 2.3333, 2.6667, 4.3333, 2.25, 2.75, 3.25, 3.75, 4.75, 4.25, 5.5, 1.3333, 3.3333, 4.6667, 1.6667, 3.6667}\n",
      "Average labels: 2.7782824016769814\n",
      "Std labels: 0.8970523348000802\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3,3, figsize=(5,8))\n",
    "subplots_adjust(right = 2, wspace=0.2, hspace=0.5, bottom=0)\n",
    "\n",
    "\n",
    "## Draw distribution of raw output\n",
    "flattened_out = output.flatten()\n",
    "print(\"Distinct output: \", set(flattened_out));\n",
    "print(\"Average labels:\", np.average(output[:,0]))\n",
    "print(\"Std labels:\", np.std(output[:,0]))\n",
    "axs[0][0].hist(output[:,0])\n",
    "axs[0][0].set_title(\"Distribution Valance\")\n",
    "axs[0][1].hist(output[:,1])\n",
    "axs[0][1].set_title(\"Distribution Arouse\")\n",
    "axs[0][2].hist(output[:,2])\n",
    "axs[0][2].set_title(\"Distribution Dominance\")\n",
    "\n",
    "\n",
    "\n",
    "## Around output into integer.\n",
    "# for i in range(0, output.size):\n",
    "#     output.flat[i] = int(np.round(output.flat[i]))\n",
    "# output = output.astype(int)\n",
    "\n",
    "# flattened_out = output.flatten()\n",
    "# print(\"\\nDistinct output: \", set(flattened_out));\n",
    "# print(\"Average labels:\", np.average(output[:,0]))\n",
    "# print(\"Std labels:\", np.std(output[:,0]))\n",
    "# axs[1][0].hist(output[:,0])\n",
    "# axs[1][0].set_title(\"Distribution Valance\")\n",
    "# axs[1][1].hist(output[:,1])\n",
    "# axs[1][1].set_title(\"Distribution Arouse\")\n",
    "# axs[1][2].hist(output[:,2])\n",
    "# axs[1][2].set_title(\"Distribution Dominance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size input, output, texts after remove Nan values  10009 ,  10009 ,  10009\n",
      "Output shape:  (10009, 3)\n",
      "Median of valance: 2.7784826755919676, arouse: 3.0911345389149765, dominance: 3.1956905884703763\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize input and categorize output \n",
      "10009\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "input_filtered = input[~np.any(np.isnan(input), axis=1)]\n",
    "input_filtered = input_filtered[:,0:88]\n",
    "output_filtered = output[~np.any(np.isnan(input), axis=1)]\n",
    "texts_filtered = texts[~np.any(np.isnan(input), axis=1)]\n",
    "print(\"Size input, output, texts after remove Nan values \", len(input_filtered), \", \", len(output_filtered), \", \", len(texts_filtered))\n",
    "\n",
    "#Normalize input\n",
    "input_filtered = (input_filtered - input_filtered.min(axis=0)) / (input_filtered.max(axis=0) - input_filtered.min(axis=0))\n",
    "\n",
    "#Normalize output\n",
    "def categorize_output(output):\n",
    "    if (output <= 2.5):\n",
    "        return 0\n",
    "    elif  output >= 4:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "# def categorize_output(output):\n",
    "#     if (output<= 3):\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "\n",
    "# def categorize_output(output):\n",
    "#     return np.around(output)\n",
    "   \n",
    "print(\"Output shape: \", output_filtered.shape)\n",
    "print(\"Median of valance: {}, arouse: {}, dominance: {}\".format(np.mean(output_filtered[:,0]), \n",
    "                                                                       np.mean(output_filtered[:,1]),\n",
    "                                                                              np.mean(output_filtered[:,2])))\n",
    "\n",
    "\n",
    "\n",
    "output_filtered = np.array([list(map(lambda x: categorize_output(x), col)) for col in output_filtered])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "subplots_adjust(right = 2, wspace=0.2, hspace=0.5, bottom=0)\n",
    "axs[0].hist(output_filtered[:,0])\n",
    "axs[0].set_title(\"Distribution Valance\")\n",
    "axs[1].hist(output_filtered[:,1])\n",
    "axs[1].set_title(\"Distribution Arouse\")\n",
    "axs[2].hist(output_filtered[:,2])\n",
    "axs[2].set_title(\"Distribution Dominance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pprint(output_filtered)\n",
    "output_filtered = [to_categorical(out, 3) for out in output_filtered]\n",
    "#output_filtered = (output_filtered - output_filtered.min(axis=0)) / (output_filtered.max(axis=0) - output_filtered.min(axis=0))\n",
    "print(\"Normalize input and categorize output \")\n",
    "print(len(output_filtered))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffer data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [1. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 1.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "#Shuffer\n",
    "c = list(zip(input_filtered, output_filtered, texts_filtered))\n",
    "random.shuffle(c)\n",
    "input_filtered, output_filtered, texts_filtered= zip( * c)\n",
    "input_filtered = np.array(input_filtered)\n",
    "output_filtered = np.array(output_filtered)\n",
    "text_filtered = np.array(texts_filtered)\n",
    "print(output_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acoustic Features Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "num_features = 88\n",
    "run = False\n",
    "\n",
    "\n",
    "if run:\n",
    "    estimator = SVR(kernel=\"linear\")\n",
    "    selector = RFE(estimator, 5, step=1)\n",
    "    output_int = np.argmax(output_filtered[:,1], axis = 1)\n",
    "    selector = selector.fit(input_filtered, output_int)\n",
    "    print(\"selection support: \", selector.support_) \n",
    "    print(\"selection ranking: \", selector.ranking_)\n",
    "\n",
    "\n",
    "selection_ranking = np.array([1, 66, 11, 73, 4, 1, 7, 47, 8, 24, 1, 23, 27, 28, 40, 41, \n",
    " 6, 78, 30, 77, 16, 84, 10, 67, 3, 54, 76, 68, 56, 65, 31, 9, 55, 81, 21, 61, 38, \n",
    " 14, 17, 39, 51, 70, 62, 79, 43, 44, 57, 22, 69, 53, 34, 83, 35, 15, 80, 42, 18, 72,\n",
    " 12, 60, 25, 52, 1, 58, 59, 64, 75, 74, 6, 33, 20, 45, 5, 29, 49, 48, 13, 32, 82, 19, 63, 36, \n",
    " 1, 2, 46, 37, 50, 71])\n",
    "\n",
    "## Get high-rank features\n",
    "input_filtered = np.array(list(map(lambda x: x[selection_ranking <= num_features], input_filtered)))\n",
    "\n",
    "num_features = len(input_filtered[0])\n",
    "print(len(input_filtered[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get Textual Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "print(a)\n",
    "[i/2 for i in a]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THEDE\\Miniconda3\\envs\\py36\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded textual features from file\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "from functools import reduce\n",
    "import timeit\n",
    "\n",
    "LOADING_TEXTUAL_FEATURES_FROM_FILE = True\n",
    "\n",
    "from liwc.LIWC_features import get_liwc_features\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "VALANCE_TYPE = ['compound', 'neg', 'neu', 'pos']\n",
    "\n",
    "def get_polarity(text):\n",
    "    ss = sid.polarity_scores(text)\n",
    "    return [ss['compound'], ss['neg'], ss['neu'], ss['pos']]\n",
    "    \n",
    "def get_liwc(text):\n",
    "    categories_freq = list(get_liwc_features(text)[0].values())\n",
    "    num_words = get_liwc_features(text)[1]\n",
    "     \n",
    "        \n",
    "    categories_freq = [x / num_words for x in categories_freq]\n",
    "    \n",
    "    return categories_freq\n",
    "\n",
    "def combine_textual_feature(*funcs):\n",
    "    \n",
    "    results = [funcs[i] for i in range (0, len(funcs))]\n",
    "    r = reduce(lambda acc, val: acc + val, results, [])\n",
    "   \n",
    "    return r\n",
    "\n",
    "\n",
    "# Writing or loading textual features\n",
    "if (not LOADING_TEXTUAL_FEATURES_FROM_FILE ):\n",
    "    textual_fearures = np.array([combine_textual_feature(get_polarity(text), get_liwc(text)) \n",
    "                             for text in text_filtered])\n",
    "    filehandler = open('processed-data/textual_features.obj', 'wb')\n",
    "    pickle.dump(textual_fearures, filehandler)\n",
    "else:\n",
    "    filehandler = open('processed-data/textual_features.obj', 'rb')\n",
    "    textual_fearures = pickle.load(filehandler)\n",
    "    print(\"Loaded textual features from file\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze all textual features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape textual features: (10009, 17). \n",
      "Sample features: [0.0616     0.209      0.57       0.22       0.         0.\n",
      " 0.         0.         0.17647059 0.05882353 0.         0.\n",
      " 0.         0.         0.         0.         0.05882353] \n"
     ]
    }
   ],
   "source": [
    "print(\"Shape textual features: {}. \\nSample features: {} \".format(textual_fearures.shape, textual_fearures[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze polarity and output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Compund values distribution of Hight valance')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_valance_int = np.argmax(output_filtered[:,0], axis=1)\n",
    "compounds = textual_fearures[:,0]\n",
    "\n",
    "\n",
    "low_valance = compounds[output_valance_int == 0]\n",
    "moderate_valance = compounds[output_valance_int == 1]\n",
    "high_valance = compounds[output_valance_int == 2]\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "subplots_adjust(right = 2, wspace=0.2, hspace=0.5, bottom=0)\n",
    "axs[0].hist(low_valance)\n",
    "axs[0].set_title(\"Compund values distribution of Low valance\")\n",
    "\n",
    "axs[1].hist(moderate_valance)\n",
    "axs[1].set_title(\"Compund values distribution of Moderate valance\")\n",
    "\n",
    "axs[2].hist(high_valance)\n",
    "axs[2].set_title(\"Compund values distribution of Hight valance\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Combine acoustic and textual **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10009, 88)\n",
      "(10009, 17)\n",
      "Length input_filtered after combination:  88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acoustic_features = input_filtered\n",
    "print(input_filtered.shape)\n",
    "print(textual_fearures.shape)\n",
    "\n",
    "#input_filtered = np.column_stack((acoustic_features, textual_fearures))\n",
    "\n",
    "print(\"Length input_filtered after combination: \", len(input_filtered[0]))\n",
    "\n",
    "#input_filtered= input_filtered[:,-1]\n",
    "num_features = len(input_filtered[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size training, testing set:  8007 ,  2002\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_filtered, output_filtered, test_size=0.2, random_state=300)\n",
    "print(\"Size training, testing set: \", len(X_train), \", \", len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Training on keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8007 samples, validate on 2002 samples\n",
      "Epoch 1/20\n",
      "8007/8007 [==============================] - ETA: 3:26 - loss: 1.0986 - acc: 0.156 - ETA: 5s - loss: 1.0953 - acc: 0.5211  - ETA: 2s - loss: 1.0921 - acc: 0.516 - ETA: 1s - loss: 1.0811 - acc: 0.523 - ETA: 1s - loss: 1.0653 - acc: 0.531 - ETA: 0s - loss: 1.0552 - acc: 0.529 - ETA: 0s - loss: 1.0426 - acc: 0.533 - ETA: 0s - loss: 1.0381 - acc: 0.532 - ETA: 0s - loss: 1.0351 - acc: 0.529 - 1s 164us/step - loss: 1.0350 - acc: 0.5285 - val_loss: 0.9962 - val_acc: 0.5450\n",
      "Epoch 2/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8701 - acc: 0.718 - ETA: 0s - loss: 1.0121 - acc: 0.526 - ETA: 0s - loss: 1.0153 - acc: 0.522 - ETA: 0s - loss: 1.0122 - acc: 0.525 - ETA: 0s - loss: 1.0132 - acc: 0.523 - ETA: 0s - loss: 1.0036 - acc: 0.532 - ETA: 0s - loss: 1.0028 - acc: 0.534 - ETA: 0s - loss: 1.0029 - acc: 0.532 - 0s 54us/step - loss: 1.0041 - acc: 0.5304 - val_loss: 0.9957 - val_acc: 0.5450\n",
      "Epoch 3/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9685 - acc: 0.593 - ETA: 0s - loss: 1.0202 - acc: 0.502 - ETA: 0s - loss: 1.0166 - acc: 0.514 - ETA: 0s - loss: 1.0122 - acc: 0.519 - ETA: 0s - loss: 1.0069 - acc: 0.521 - ETA: 0s - loss: 1.0086 - acc: 0.522 - ETA: 0s - loss: 1.0026 - acc: 0.529 - ETA: 0s - loss: 1.0011 - acc: 0.531 - ETA: 0s - loss: 1.0027 - acc: 0.530 - 0s 56us/step - loss: 1.0027 - acc: 0.5304 - val_loss: 0.9927 - val_acc: 0.5450\n",
      "Epoch 4/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.1106 - acc: 0.406 - ETA: 0s - loss: 0.9871 - acc: 0.548 - ETA: 0s - loss: 0.9862 - acc: 0.549 - ETA: 0s - loss: 0.9904 - acc: 0.543 - ETA: 0s - loss: 0.9928 - acc: 0.539 - ETA: 0s - loss: 0.9991 - acc: 0.533 - ETA: 0s - loss: 0.9998 - acc: 0.531 - ETA: 0s - loss: 0.9965 - acc: 0.534 - ETA: 0s - loss: 1.0011 - acc: 0.530 - 0s 58us/step - loss: 1.0012 - acc: 0.5304 - val_loss: 0.9948 - val_acc: 0.5450\n",
      "Epoch 5/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9652 - acc: 0.593 - ETA: 0s - loss: 1.0127 - acc: 0.521 - ETA: 0s - loss: 1.0072 - acc: 0.521 - ETA: 0s - loss: 1.0018 - acc: 0.525 - ETA: 0s - loss: 1.0027 - acc: 0.526 - ETA: 0s - loss: 1.0018 - acc: 0.528 - ETA: 0s - loss: 0.9994 - acc: 0.531 - ETA: 0s - loss: 0.9992 - acc: 0.531 - 0s 51us/step - loss: 1.0000 - acc: 0.5304 - val_loss: 0.9892 - val_acc: 0.5450\n",
      "Epoch 6/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.1331 - acc: 0.375 - ETA: 0s - loss: 0.9825 - acc: 0.547 - ETA: 0s - loss: 0.9964 - acc: 0.534 - ETA: 0s - loss: 0.9970 - acc: 0.530 - ETA: 0s - loss: 0.9976 - acc: 0.529 - ETA: 0s - loss: 0.9988 - acc: 0.528 - ETA: 0s - loss: 0.9978 - acc: 0.530 - ETA: 0s - loss: 0.9972 - acc: 0.530 - 0s 50us/step - loss: 0.9976 - acc: 0.5304 - val_loss: 0.9870 - val_acc: 0.5450\n",
      "Epoch 7/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9100 - acc: 0.625 - ETA: 0s - loss: 0.9834 - acc: 0.553 - ETA: 0s - loss: 0.9985 - acc: 0.529 - ETA: 0s - loss: 0.9988 - acc: 0.529 - ETA: 0s - loss: 1.0029 - acc: 0.525 - ETA: 0s - loss: 0.9992 - acc: 0.530 - ETA: 0s - loss: 1.0009 - acc: 0.527 - ETA: 0s - loss: 0.9977 - acc: 0.528 - 0s 52us/step - loss: 0.9949 - acc: 0.5304 - val_loss: 0.9866 - val_acc: 0.5450\n",
      "Epoch 8/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8358 - acc: 0.593 - ETA: 0s - loss: 0.9954 - acc: 0.520 - ETA: 0s - loss: 1.0020 - acc: 0.519 - ETA: 0s - loss: 0.9900 - acc: 0.531 - ETA: 0s - loss: 0.9918 - acc: 0.528 - ETA: 0s - loss: 0.9940 - acc: 0.529 - ETA: 0s - loss: 0.9914 - acc: 0.532 - ETA: 0s - loss: 0.9920 - acc: 0.530 - 0s 52us/step - loss: 0.9911 - acc: 0.5304 - val_loss: 0.9793 - val_acc: 0.5450\n",
      "Epoch 9/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.0135 - acc: 0.468 - ETA: 0s - loss: 1.0022 - acc: 0.519 - ETA: 0s - loss: 0.9799 - acc: 0.538 - ETA: 0s - loss: 0.9851 - acc: 0.532 - ETA: 0s - loss: 0.9877 - acc: 0.529 - ETA: 0s - loss: 0.9872 - acc: 0.530 - ETA: 0s - loss: 0.9860 - acc: 0.531 - ETA: 0s - loss: 0.9859 - acc: 0.531 - 0s 54us/step - loss: 0.9864 - acc: 0.5312 - val_loss: 0.9750 - val_acc: 0.5455\n",
      "Epoch 10/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8832 - acc: 0.625 - ETA: 0s - loss: 0.9657 - acc: 0.546 - ETA: 0s - loss: 0.9784 - acc: 0.538 - ETA: 0s - loss: 0.9841 - acc: 0.535 - ETA: 0s - loss: 0.9840 - acc: 0.531 - ETA: 0s - loss: 0.9833 - acc: 0.530 - ETA: 0s - loss: 0.9799 - acc: 0.534 - ETA: 0s - loss: 0.9826 - acc: 0.531 - 0s 56us/step - loss: 0.9819 - acc: 0.5328 - val_loss: 0.9740 - val_acc: 0.5450\n",
      "Epoch 11/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9252 - acc: 0.625 - ETA: 0s - loss: 0.9740 - acc: 0.537 - ETA: 0s - loss: 0.9882 - acc: 0.522 - ETA: 0s - loss: 0.9847 - acc: 0.527 - ETA: 0s - loss: 0.9845 - acc: 0.529 - ETA: 0s - loss: 0.9793 - acc: 0.533 - ETA: 0s - loss: 0.9807 - acc: 0.533 - ETA: 0s - loss: 0.9800 - acc: 0.534 - ETA: 0s - loss: 0.9788 - acc: 0.534 - 0s 58us/step - loss: 0.9806 - acc: 0.5340 - val_loss: 0.9734 - val_acc: 0.5450\n",
      "Epoch 12/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.1303 - acc: 0.468 - ETA: 0s - loss: 0.9861 - acc: 0.538 - ETA: 0s - loss: 0.9802 - acc: 0.542 - ETA: 0s - loss: 0.9830 - acc: 0.536 - ETA: 0s - loss: 0.9803 - acc: 0.534 - ETA: 0s - loss: 0.9825 - acc: 0.530 - ETA: 0s - loss: 0.9818 - acc: 0.532 - ETA: 0s - loss: 0.9783 - acc: 0.535 - ETA: 0s - loss: 0.9780 - acc: 0.536 - 0s 60us/step - loss: 0.9789 - acc: 0.5355 - val_loss: 0.9714 - val_acc: 0.5490\n",
      "Epoch 13/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9373 - acc: 0.593 - ETA: 0s - loss: 0.9908 - acc: 0.532 - ETA: 0s - loss: 0.9822 - acc: 0.529 - ETA: 0s - loss: 0.9793 - acc: 0.527 - ETA: 0s - loss: 0.9766 - acc: 0.534 - ETA: 0s - loss: 0.9809 - acc: 0.533 - ETA: 0s - loss: 0.9780 - acc: 0.535 - ETA: 0s - loss: 0.9771 - acc: 0.535 - ETA: 0s - loss: 0.9774 - acc: 0.535 - ETA: 0s - loss: 0.9777 - acc: 0.537 - 1s 63us/step - loss: 0.9782 - acc: 0.5374 - val_loss: 0.9708 - val_acc: 0.5495\n",
      "Epoch 14/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9967 - acc: 0.531 - ETA: 0s - loss: 0.9897 - acc: 0.531 - ETA: 0s - loss: 0.9911 - acc: 0.527 - ETA: 0s - loss: 0.9843 - acc: 0.537 - ETA: 0s - loss: 0.9794 - acc: 0.542 - ETA: 0s - loss: 0.9761 - acc: 0.545 - ETA: 0s - loss: 0.9726 - acc: 0.545 - ETA: 0s - loss: 0.9732 - acc: 0.546 - ETA: 0s - loss: 0.9757 - acc: 0.542 - 0s 61us/step - loss: 0.9765 - acc: 0.5403 - val_loss: 0.9706 - val_acc: 0.5490\n",
      "Epoch 15/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.0619 - acc: 0.437 - ETA: 0s - loss: 0.9861 - acc: 0.531 - ETA: 0s - loss: 0.9869 - acc: 0.538 - ETA: 0s - loss: 0.9901 - acc: 0.533 - ETA: 0s - loss: 0.9809 - acc: 0.541 - ETA: 0s - loss: 0.9777 - acc: 0.542 - ETA: 0s - loss: 0.9771 - acc: 0.543 - ETA: 0s - loss: 0.9740 - acc: 0.543 - ETA: 0s - loss: 0.9739 - acc: 0.544 - 0s 62us/step - loss: 0.9754 - acc: 0.5412 - val_loss: 0.9745 - val_acc: 0.5529\n",
      "Epoch 16/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9014 - acc: 0.562 - ETA: 0s - loss: 0.9953 - acc: 0.520 - ETA: 0s - loss: 0.9945 - acc: 0.526 - ETA: 0s - loss: 0.9859 - acc: 0.537 - ETA: 0s - loss: 0.9845 - acc: 0.537 - ETA: 0s - loss: 0.9773 - acc: 0.542 - ETA: 0s - loss: 0.9727 - acc: 0.543 - ETA: 0s - loss: 0.9758 - acc: 0.541 - ETA: 0s - loss: 0.9780 - acc: 0.539 - ETA: 0s - loss: 0.9768 - acc: 0.540 - 1s 66us/step - loss: 0.9752 - acc: 0.5414 - val_loss: 0.9678 - val_acc: 0.5519\n",
      "Epoch 17/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.1129 - acc: 0.406 - ETA: 0s - loss: 1.0050 - acc: 0.507 - ETA: 0s - loss: 0.9958 - acc: 0.526 - ETA: 0s - loss: 0.9862 - acc: 0.538 - ETA: 0s - loss: 0.9777 - acc: 0.541 - ETA: 0s - loss: 0.9789 - acc: 0.540 - ETA: 0s - loss: 0.9748 - acc: 0.544 - ETA: 0s - loss: 0.9747 - acc: 0.544 - ETA: 0s - loss: 0.9737 - acc: 0.546 - 0s 60us/step - loss: 0.9741 - acc: 0.5445 - val_loss: 0.9699 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9470 - acc: 0.562 - ETA: 0s - loss: 0.9677 - acc: 0.544 - ETA: 0s - loss: 0.9681 - acc: 0.551 - ETA: 0s - loss: 0.9679 - acc: 0.550 - ETA: 0s - loss: 0.9735 - acc: 0.544 - ETA: 0s - loss: 0.9762 - acc: 0.542 - ETA: 0s - loss: 0.9727 - acc: 0.547 - ETA: 0s - loss: 0.9725 - acc: 0.546 - ETA: 0s - loss: 0.9733 - acc: 0.545 - 0s 61us/step - loss: 0.9733 - acc: 0.5451 - val_loss: 0.9680 - val_acc: 0.5564\n",
      "Epoch 19/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9682 - acc: 0.562 - ETA: 0s - loss: 0.9795 - acc: 0.537 - ETA: 0s - loss: 0.9846 - acc: 0.535 - ETA: 0s - loss: 0.9798 - acc: 0.542 - ETA: 0s - loss: 0.9745 - acc: 0.545 - ETA: 0s - loss: 0.9730 - acc: 0.546 - ETA: 0s - loss: 0.9698 - acc: 0.547 - ETA: 0s - loss: 0.9728 - acc: 0.546 - ETA: 0s - loss: 0.9730 - acc: 0.548 - ETA: 0s - loss: 0.9728 - acc: 0.547 - 1s 63us/step - loss: 0.9727 - acc: 0.5469 - val_loss: 0.9666 - val_acc: 0.5569\n",
      "Epoch 20/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.0724 - acc: 0.500 - ETA: 0s - loss: 0.9749 - acc: 0.541 - ETA: 0s - loss: 0.9797 - acc: 0.538 - ETA: 0s - loss: 0.9782 - acc: 0.540 - ETA: 0s - loss: 0.9742 - acc: 0.546 - ETA: 0s - loss: 0.9693 - acc: 0.551 - ETA: 0s - loss: 0.9692 - acc: 0.550 - ETA: 0s - loss: 0.9709 - acc: 0.548 - ETA: 0s - loss: 0.9727 - acc: 0.548 - ETA: 0s - loss: 0.9740 - acc: 0.546 - 1s 66us/step - loss: 0.9709 - acc: 0.5488 - val_loss: 0.9669 - val_acc: 0.5544\n",
      "Train on 8007 samples, validate on 2002 samples\n",
      "Epoch 1/20\n",
      "8007/8007 [==============================] - ETA: 2:24 - loss: 1.0986 - acc: 0.312 - ETA: 5s - loss: 1.0965 - acc: 0.3887  - ETA: 2s - loss: 1.0945 - acc: 0.386 - ETA: 1s - loss: 1.0938 - acc: 0.369 - ETA: 1s - loss: 1.0865 - acc: 0.372 - ETA: 0s - loss: 1.0743 - acc: 0.380 - ETA: 0s - loss: 1.0679 - acc: 0.385 - ETA: 0s - loss: 1.0595 - acc: 0.393 - ETA: 0s - loss: 1.0513 - acc: 0.401 - ETA: 0s - loss: 1.0439 - acc: 0.410 - 1s 145us/step - loss: 1.0380 - acc: 0.4166 - val_loss: 0.9874 - val_acc: 0.4845\n",
      "Epoch 2/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9259 - acc: 0.406 - ETA: 0s - loss: 0.9692 - acc: 0.555 - ETA: 0s - loss: 0.9719 - acc: 0.556 - ETA: 0s - loss: 0.9729 - acc: 0.558 - ETA: 0s - loss: 0.9683 - acc: 0.556 - ETA: 0s - loss: 0.9691 - acc: 0.553 - ETA: 0s - loss: 0.9678 - acc: 0.557 - ETA: 0s - loss: 0.9679 - acc: 0.557 - ETA: 0s - loss: 0.9663 - acc: 0.558 - ETA: 0s - loss: 0.9654 - acc: 0.555 - 1s 63us/step - loss: 0.9646 - acc: 0.5560 - val_loss: 0.9522 - val_acc: 0.5604\n",
      "Epoch 3/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9242 - acc: 0.593 - ETA: 0s - loss: 0.9394 - acc: 0.585 - ETA: 0s - loss: 0.9400 - acc: 0.585 - ETA: 0s - loss: 0.9399 - acc: 0.583 - ETA: 0s - loss: 0.9453 - acc: 0.571 - ETA: 0s - loss: 0.9420 - acc: 0.574 - ETA: 0s - loss: 0.9373 - acc: 0.574 - ETA: 0s - loss: 0.9380 - acc: 0.571 - ETA: 0s - loss: 0.9367 - acc: 0.569 - ETA: 0s - loss: 0.9355 - acc: 0.570 - 1s 68us/step - loss: 0.9345 - acc: 0.5691 - val_loss: 0.9830 - val_acc: 0.4960\n",
      "Epoch 4/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9387 - acc: 0.593 - ETA: 0s - loss: 0.9469 - acc: 0.554 - ETA: 0s - loss: 0.9257 - acc: 0.577 - ETA: 0s - loss: 0.9271 - acc: 0.570 - ETA: 0s - loss: 0.9225 - acc: 0.574 - ETA: 0s - loss: 0.9226 - acc: 0.575 - ETA: 0s - loss: 0.9197 - acc: 0.575 - ETA: 0s - loss: 0.9191 - acc: 0.574 - ETA: 0s - loss: 0.9186 - acc: 0.570 - ETA: 0s - loss: 0.9187 - acc: 0.569 - ETA: 0s - loss: 0.9171 - acc: 0.568 - 1s 75us/step - loss: 0.9153 - acc: 0.5688 - val_loss: 0.9142 - val_acc: 0.5854\n",
      "Epoch 5/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8833 - acc: 0.562 - ETA: 0s - loss: 0.9153 - acc: 0.551 - ETA: 0s - loss: 0.9063 - acc: 0.571 - ETA: 0s - loss: 0.9026 - acc: 0.577 - ETA: 0s - loss: 0.9049 - acc: 0.573 - ETA: 0s - loss: 0.9047 - acc: 0.575 - ETA: 0s - loss: 0.9054 - acc: 0.572 - ETA: 0s - loss: 0.9055 - acc: 0.573 - ETA: 0s - loss: 0.9010 - acc: 0.577 - ETA: 0s - loss: 0.8991 - acc: 0.579 - ETA: 0s - loss: 0.8994 - acc: 0.578 - 1s 71us/step - loss: 0.8996 - acc: 0.5779 - val_loss: 0.9587 - val_acc: 0.5100\n",
      "Epoch 6/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9063 - acc: 0.656 - ETA: 0s - loss: 0.8788 - acc: 0.563 - ETA: 0s - loss: 0.8737 - acc: 0.583 - ETA: 0s - loss: 0.8785 - acc: 0.587 - ETA: 0s - loss: 0.8783 - acc: 0.583 - ETA: 0s - loss: 0.8814 - acc: 0.582 - ETA: 0s - loss: 0.8842 - acc: 0.581 - ETA: 0s - loss: 0.8846 - acc: 0.578 - ETA: 0s - loss: 0.8868 - acc: 0.576 - ETA: 0s - loss: 0.8868 - acc: 0.577 - ETA: 0s - loss: 0.8881 - acc: 0.576 - 1s 75us/step - loss: 0.8890 - acc: 0.5752 - val_loss: 0.9035 - val_acc: 0.5699\n",
      "Epoch 7/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8717 - acc: 0.468 - ETA: 0s - loss: 0.8770 - acc: 0.578 - ETA: 0s - loss: 0.8796 - acc: 0.578 - ETA: 0s - loss: 0.8814 - acc: 0.578 - ETA: 0s - loss: 0.8834 - acc: 0.576 - ETA: 0s - loss: 0.8819 - acc: 0.578 - ETA: 0s - loss: 0.8828 - acc: 0.578 - ETA: 0s - loss: 0.8842 - acc: 0.579 - ETA: 0s - loss: 0.8826 - acc: 0.582 - ETA: 0s - loss: 0.8822 - acc: 0.581 - ETA: 0s - loss: 0.8819 - acc: 0.580 - 1s 70us/step - loss: 0.8824 - acc: 0.5807 - val_loss: 0.8934 - val_acc: 0.5824\n",
      "Epoch 8/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9323 - acc: 0.593 - ETA: 0s - loss: 0.8829 - acc: 0.577 - ETA: 0s - loss: 0.8607 - acc: 0.598 - ETA: 0s - loss: 0.8735 - acc: 0.588 - ETA: 0s - loss: 0.8760 - acc: 0.585 - ETA: 0s - loss: 0.8748 - acc: 0.582 - ETA: 0s - loss: 0.8788 - acc: 0.580 - ETA: 0s - loss: 0.8819 - acc: 0.577 - ETA: 0s - loss: 0.8800 - acc: 0.580 - 0s 61us/step - loss: 0.8792 - acc: 0.5804 - val_loss: 0.9186 - val_acc: 0.5405\n",
      "Epoch 9/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 1.0217 - acc: 0.437 - ETA: 0s - loss: 0.8612 - acc: 0.593 - ETA: 0s - loss: 0.8621 - acc: 0.605 - ETA: 0s - loss: 0.8672 - acc: 0.595 - ETA: 0s - loss: 0.8757 - acc: 0.588 - ETA: 0s - loss: 0.8738 - acc: 0.590 - ETA: 0s - loss: 0.8751 - acc: 0.586 - ETA: 0s - loss: 0.8754 - acc: 0.585 - ETA: 0s - loss: 0.8758 - acc: 0.581 - 0s 60us/step - loss: 0.8739 - acc: 0.5827 - val_loss: 0.8843 - val_acc: 0.5879\n",
      "Epoch 10/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9202 - acc: 0.562 - ETA: 0s - loss: 0.8764 - acc: 0.577 - ETA: 0s - loss: 0.8664 - acc: 0.582 - ETA: 0s - loss: 0.8719 - acc: 0.590 - ETA: 0s - loss: 0.8701 - acc: 0.592 - ETA: 0s - loss: 0.8651 - acc: 0.593 - ETA: 0s - loss: 0.8674 - acc: 0.591 - ETA: 0s - loss: 0.8719 - acc: 0.589 - ETA: 0s - loss: 0.8692 - acc: 0.589 - ETA: 0s - loss: 0.8683 - acc: 0.589 - 1s 63us/step - loss: 0.8684 - acc: 0.5892 - val_loss: 0.8972 - val_acc: 0.5619\n",
      "Epoch 11/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.7278 - acc: 0.656 - ETA: 0s - loss: 0.8816 - acc: 0.583 - ETA: 0s - loss: 0.8826 - acc: 0.568 - ETA: 0s - loss: 0.8757 - acc: 0.578 - ETA: 0s - loss: 0.8753 - acc: 0.577 - ETA: 0s - loss: 0.8702 - acc: 0.581 - ETA: 0s - loss: 0.8727 - acc: 0.578 - ETA: 0s - loss: 0.8716 - acc: 0.579 - ETA: 0s - loss: 0.8664 - acc: 0.582 - ETA: 0s - loss: 0.8681 - acc: 0.580 - 1s 64us/step - loss: 0.8678 - acc: 0.5797 - val_loss: 0.8840 - val_acc: 0.5904\n",
      "Epoch 12/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9503 - acc: 0.437 - ETA: 0s - loss: 0.8534 - acc: 0.576 - ETA: 0s - loss: 0.8848 - acc: 0.563 - ETA: 0s - loss: 0.8689 - acc: 0.583 - ETA: 0s - loss: 0.8703 - acc: 0.582 - ETA: 0s - loss: 0.8660 - acc: 0.583 - ETA: 0s - loss: 0.8672 - acc: 0.582 - ETA: 0s - loss: 0.8677 - acc: 0.583 - ETA: 0s - loss: 0.8682 - acc: 0.583 - ETA: 0s - loss: 0.8692 - acc: 0.582 - 1s 64us/step - loss: 0.8683 - acc: 0.5829 - val_loss: 0.8821 - val_acc: 0.5819\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9892 - acc: 0.531 - ETA: 0s - loss: 0.8869 - acc: 0.595 - ETA: 0s - loss: 0.8965 - acc: 0.566 - ETA: 0s - loss: 0.8796 - acc: 0.577 - ETA: 0s - loss: 0.8774 - acc: 0.573 - ETA: 0s - loss: 0.8689 - acc: 0.582 - ETA: 0s - loss: 0.8706 - acc: 0.582 - ETA: 0s - loss: 0.8676 - acc: 0.584 - ETA: 0s - loss: 0.8687 - acc: 0.584 - ETA: 0s - loss: 0.8681 - acc: 0.582 - 1s 68us/step - loss: 0.8648 - acc: 0.5852 - val_loss: 0.8759 - val_acc: 0.5909\n",
      "Epoch 14/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9128 - acc: 0.468 - ETA: 0s - loss: 0.8703 - acc: 0.601 - ETA: 0s - loss: 0.8689 - acc: 0.594 - ETA: 0s - loss: 0.8682 - acc: 0.593 - ETA: 0s - loss: 0.8666 - acc: 0.586 - ETA: 0s - loss: 0.8676 - acc: 0.585 - ETA: 0s - loss: 0.8671 - acc: 0.584 - ETA: 0s - loss: 0.8649 - acc: 0.586 - ETA: 0s - loss: 0.8615 - acc: 0.586 - ETA: 0s - loss: 0.8600 - acc: 0.589 - 1s 66us/step - loss: 0.8619 - acc: 0.5864 - val_loss: 0.8737 - val_acc: 0.5964\n",
      "Epoch 15/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8594 - acc: 0.593 - ETA: 0s - loss: 0.8484 - acc: 0.597 - ETA: 0s - loss: 0.8483 - acc: 0.585 - ETA: 0s - loss: 0.8505 - acc: 0.591 - ETA: 0s - loss: 0.8558 - acc: 0.588 - ETA: 0s - loss: 0.8547 - acc: 0.586 - ETA: 0s - loss: 0.8572 - acc: 0.584 - ETA: 0s - loss: 0.8529 - acc: 0.586 - ETA: 0s - loss: 0.8542 - acc: 0.586 - ETA: 0s - loss: 0.8558 - acc: 0.587 - 1s 67us/step - loss: 0.8575 - acc: 0.5866 - val_loss: 0.8762 - val_acc: 0.5869\n",
      "Epoch 16/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9410 - acc: 0.531 - ETA: 0s - loss: 0.8698 - acc: 0.584 - ETA: 0s - loss: 0.8530 - acc: 0.585 - ETA: 0s - loss: 0.8528 - acc: 0.586 - ETA: 0s - loss: 0.8567 - acc: 0.581 - ETA: 0s - loss: 0.8644 - acc: 0.578 - ETA: 0s - loss: 0.8675 - acc: 0.575 - ETA: 0s - loss: 0.8680 - acc: 0.574 - ETA: 0s - loss: 0.8670 - acc: 0.577 - 0s 60us/step - loss: 0.8670 - acc: 0.5796 - val_loss: 0.8869 - val_acc: 0.5779\n",
      "Epoch 17/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9662 - acc: 0.531 - ETA: 0s - loss: 0.8443 - acc: 0.597 - ETA: 0s - loss: 0.8542 - acc: 0.589 - ETA: 0s - loss: 0.8599 - acc: 0.588 - ETA: 0s - loss: 0.8650 - acc: 0.585 - ETA: 0s - loss: 0.8562 - acc: 0.588 - ETA: 0s - loss: 0.8519 - acc: 0.591 - ETA: 0s - loss: 0.8514 - acc: 0.592 - ETA: 0s - loss: 0.8544 - acc: 0.591 - ETA: 0s - loss: 0.8582 - acc: 0.586 - 1s 64us/step - loss: 0.8585 - acc: 0.5861 - val_loss: 0.8733 - val_acc: 0.5904\n",
      "Epoch 18/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.9216 - acc: 0.375 - ETA: 0s - loss: 0.8347 - acc: 0.580 - ETA: 0s - loss: 0.8361 - acc: 0.594 - ETA: 0s - loss: 0.8429 - acc: 0.587 - ETA: 0s - loss: 0.8410 - acc: 0.589 - ETA: 0s - loss: 0.8465 - acc: 0.588 - ETA: 0s - loss: 0.8477 - acc: 0.592 - ETA: 0s - loss: 0.8468 - acc: 0.591 - ETA: 0s - loss: 0.8484 - acc: 0.591 - ETA: 0s - loss: 0.8519 - acc: 0.589 - 1s 67us/step - loss: 0.8526 - acc: 0.5890 - val_loss: 0.8698 - val_acc: 0.5884\n",
      "Epoch 19/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8014 - acc: 0.656 - ETA: 0s - loss: 0.8687 - acc: 0.587 - ETA: 0s - loss: 0.8737 - acc: 0.583 - ETA: 0s - loss: 0.8601 - acc: 0.590 - ETA: 0s - loss: 0.8617 - acc: 0.588 - ETA: 0s - loss: 0.8619 - acc: 0.589 - ETA: 0s - loss: 0.8549 - acc: 0.592 - ETA: 0s - loss: 0.8547 - acc: 0.592 - ETA: 0s - loss: 0.8524 - acc: 0.590 - 0s 60us/step - loss: 0.8528 - acc: 0.5891 - val_loss: 0.8738 - val_acc: 0.5834\n",
      "Epoch 20/20\n",
      "8007/8007 [==============================] - ETA: 0s - loss: 0.8583 - acc: 0.531 - ETA: 0s - loss: 0.8858 - acc: 0.558 - ETA: 0s - loss: 0.8565 - acc: 0.573 - ETA: 0s - loss: 0.8539 - acc: 0.576 - ETA: 0s - loss: 0.8524 - acc: 0.578 - ETA: 0s - loss: 0.8547 - acc: 0.579 - ETA: 0s - loss: 0.8580 - acc: 0.578 - ETA: 0s - loss: 0.8568 - acc: 0.580 - ETA: 0s - loss: 0.8540 - acc: 0.584 - ETA: 0s - loss: 0.8532 - acc: 0.585 - 1s 68us/step - loss: 0.8516 - acc: 0.5870 - val_loss: 0.8712 - val_acc: 0.5899\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/device:CPU:0'):\n",
    "    model = Sequential([\n",
    "        Dense(3, input_shape=(num_features,), kernel_initializer='normal'),\n",
    "       Activation('relu'),\n",
    "        Dense(32, kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(16,kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(8, kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(3,kernel_initializer='normal'),\n",
    "         Activation('sigmoid'),\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    model.fit(X_train, y_train[:,0], validation_data=(X_test, y_test[:,0]), epochs = 20)\n",
    "   \n",
    "        \n",
    "    \n",
    "    \n",
    "    # Remove lable 1.\n",
    "#     condition_train =  [y==0 or y ==1 for y in np.argmax(y_train[:,1], axis=1)] \n",
    "#     condition_test = [y==0 or y ==1 for y in np.argmax(y_test[:,1], axis=1)] \n",
    "#     X_train_1 = X_train[condition_train]\n",
    "#     y_train_1 = y_train[condition_train]\n",
    "#     X_test_1 = X_test[condition_test]\n",
    "#     y_test_1 = y_test[condition_test]\n",
    "    \n",
    "#     print(y_test_1)\n",
    "\n",
    "    model1 = Sequential([\n",
    "        Dense(64, input_shape=(num_features,), kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(32, kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(16,kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(8, kernel_initializer='normal'),\n",
    "        Activation('relu'),\n",
    "        Dense(3),\n",
    "        Activation('softmax'),\n",
    "\n",
    "    ])\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    model1.fit(X_train, y_train[:,1], validation_data=(X_test, y_test[:,1]), epochs = 20)\n",
    "\n",
    "\n",
    "#     model2 = Sequential([\n",
    "#         Dense(64, input_shape=(20,), kernel_initializer='normal'),\n",
    "#         Activation('relu'),\n",
    "#         Dense(32, kernel_initializer='normal'),\n",
    "#         Activation('relu'),\n",
    "#         Dense(16,kernel_initializer='normal'),\n",
    "#         Activation('relu'),\n",
    "#         Dense(8, kernel_initializer='normal'),\n",
    "#         Activation('relu'),\n",
    "#         Dense(1),\n",
    "#     ])\n",
    "#     model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     model2.fit(X_train, y_train[:,2], validation_data=(X_test, y_test[:,2]), epochs = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1073    0   18]\n",
      " [ 351    0   24]\n",
      " [ 499    0   37]] \n",
      "\n",
      "[[428 113  51]\n",
      " [224 235 152]\n",
      " [ 82 199 518]]\n",
      "[0.3776621  0.39088276 0.2314552 ] ,  2\n",
      "[0.27020496 0.4202352  0.30955982] ,  1\n",
      "[0.6336852  0.26807326 0.09824164] ,  0\n",
      "[0.5749157  0.3012552  0.12382904] ,  1\n",
      "[0.19693856 0.42707384 0.37598768] ,  2\n",
      "[0.10293256 0.31597322 0.58109415] ,  2\n",
      "[0.703557   0.22532132 0.07112163] ,  1\n",
      "[0.01644134 0.13800359 0.84555507] ,  1\n",
      "[0.12750664 0.35190716 0.5205862 ] ,  1\n",
      "[0.625252   0.27299392 0.10175402] ,  0\n",
      "[0.04321104 0.20841335 0.7483756 ] ,  2\n",
      "[0.27337015 0.41965243 0.30697742] ,  1\n",
      "[0.3274318 0.406853  0.2657152] ,  1\n",
      "[0.06450802 0.25459477 0.68089724] ,  2\n",
      "[0.2980522  0.41444305 0.2875048 ] ,  0\n",
      "[0.703557   0.22532132 0.07112163] ,  0\n",
      "[0.414725   0.37702498 0.20825008] ,  0\n",
      "[0.14362149 0.37452942 0.48184907] ,  2\n",
      "[0.40515476 0.38075766 0.21408758] ,  1\n",
      "[0.631619   0.26928368 0.09909738] ,  0\n",
      "Log_loss: 0.8712123276196656\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-388a72a2b2af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Log_loss:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0my_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "pre = model.predict_classes(X_test)\n",
    "y_int = np.argmax(y_test[:,0], axis=1)\n",
    "print(confusion_matrix(y_int, pre), \"\\n\")\n",
    "\n",
    "\n",
    "pre = model1.predict_classes(X_test)\n",
    "#pre = model1.predict(X_test)\n",
    "#pre = np.argmax(pre, axis =1)\n",
    "y_int = np.argmax(y_test[:,1], axis=1)\n",
    "print(confusion_matrix(y_int, pre))\n",
    "prob =  model1.predict(X_test)\n",
    "for i in range(0,20):\n",
    "    print(prob[i],\", \" ,y_int[i])\n",
    "print(\"Log_loss:\",log_loss(y_int, prob))\n",
    "\n",
    "pre = model2.predict_classes(X_test)\n",
    "y_int = np.argmax(y_test[:,2], axis=1)\n",
    "print(\"\\n\",confusion_matrix(y_int, pre))\n",
    "\n",
    "\n",
    "# [[1001    0   62]\n",
    "#  [ 462    0   87]\n",
    "#  [ 261    0  129]] \n",
    "\n",
    "# [[383 240   4]\n",
    "#  [197 813  40]\n",
    "#  [  8 200 117]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinal logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mord\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "\n",
    "clf2 = mord.LogisticAT(alpha=1)\n",
    "#clf2 = mord.LogisticIT(alpha=1)\n",
    "#clf2 = mord.LAD()\n",
    "#clf2 = mord.OrdinalRidge()\n",
    "#clf2 = mord.MulticlassLogistic()\n",
    "\n",
    "y_train_AT = y_train \n",
    "y_train_AT = y_train_AT.astype(int)\n",
    "y_test_AT = y_test.astype(int)\n",
    "\n",
    "clf2.fit(X_train, y_train_AT[:,1])\n",
    "\n",
    "print(metrics.mean_absolute_error(model1.predict(X_test), y_test_AT[:,1]))\n",
    "print('Mean Absolute Error of LogisticAT %s' % metrics.mean_absolute_error(clf2.predict(X_test), y_test_AT[:,1]))\n",
    "\n",
    "print(clf2.predict(X_test)[0:3])\n",
    "#print(clf2.predict_proba(X_test)[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient of Determination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#predict = model.predict(X_test)\n",
    "predict1 = model1.predict(X_test)\n",
    "#predict2 = model2.predict(X_test)\n",
    "\n",
    "# a = r2_score(y_test[:,0], predict)\n",
    "# print(\"The R2 for Valance: \" ,a)\n",
    "\n",
    "a1 = r2_score(y_test[:,1], predict1)\n",
    "print(\"The R2 for Activation: \" ,a1)\n",
    "\n",
    "# a2 = r2_score(y_test[:,2], predict2)\n",
    "# print(\"The R2 for Dominance: \" ,a2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of err**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.linspace(0, 1, 10)\n",
    "data = np.abs(predict1 - y_test[:,1])\n",
    "print(len(data))\n",
    "hist, bin_edges = np.histogram(data,bins) # make the histogram\n",
    "print(hist)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Plot the histogram heights against integers on the x axis\n",
    "ax.bar(range(len(hist)),hist,width=1) \n",
    "\n",
    "# # Set the ticks to the middle of the bars\n",
    "# ax.set_xticks([0.5+i for i,j in enumerate(hist)])\n",
    "\n",
    "# # # Set the xticklabels to a string that tells us what the bin edges were\n",
    "# # ax.set_xticklabels(['{} - {}'.format(bins[i],bins[i+1]) for i,j in enumerate(hist)])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#predict = model.predict(X_test)\n",
    "\n",
    "#plt.hist(subs, bins =bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard residual plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots_adjust\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "subplots_adjust(right = 2, wspace=0.2)\n",
    "predict = model.predict(X_test)\n",
    "predict = np.array([p[0] for p in predict])\n",
    "axs[0] = sns.residplot(y_test[:,0], predict, lowess=True, color=\"g\", ax=axs[0])\n",
    "axs[0].set_ylim([-0.4,0.4])\n",
    "axs[0].set_title(\"Residual for Valance\") \n",
    "\n",
    "\n",
    "predict1 = model1.predict(X_test)\n",
    "predict1 = np.array([p[0] for p in predict1])\n",
    "axs[1] = sns.residplot(y_test[:,1], predict1, lowess=True, color=\"r\", ax=axs[1])\n",
    "axs[1].set_ylim([-0.4,0.4])\n",
    "axs[1].set_title(\"Residual for Activation\")\n",
    "\n",
    "predict2 = model2.predict(X_test)\n",
    "predict2 = np.array([p[0] for p in predict2])\n",
    "axs[2] = sns.residplot(y_test[:,2], predict2, lowess=True, color=\"b\", ax=axs[2])\n",
    "axs[2].set_ylim([-0.5,0.5])\n",
    "axs[2].set_title(\"Residual for Dominance\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual plot show that the error followed random pattern. If the residual plot is not enough random, then the model would be likely to lose something. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Playing around with prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict = model.predict(X_test)\n",
    "#print(predict)\n",
    "\n",
    "subs = np.abs(predict - y_test[:,0])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "subplots_adjust(right = 2, wspace=0.2)\n",
    "axs[0].hist(y_train[:,0])\n",
    "axs[0].set_title(\"True value in train data\\n\" + \n",
    "                 \"avg:\" + str(np.average(y_train[:,0])) + \n",
    "                 \"\\nstd:\" + str(np.std(y_train[:,0])))\n",
    "axs[1].hist(y_test[:,0])\n",
    "axs[1].set_title(\"True value in test data\\n\" + \n",
    "                 \"avg:\" + str(np.average(y_test[:,0])) + \n",
    "                 \"\\nstd:\" + str(np.std(y_test[:,0])))\n",
    "axs[1].set_ylim([0,400])\n",
    "                        \n",
    "axs[2].hist(predict) \n",
    "axs[2].set_title(\"Prediction\\n\" +\n",
    "                \"avg:\" + str(np.average(predict)) + \n",
    "                 \"\\nstd:\" + str(np.std(predict)))\n",
    "                \n",
    "# axs[2].hist(subs, bins='auto')\n",
    "# axs[2].set_title(\"error on predictions\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.99):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "predict = model1.predict(X_test)\n",
    "bins = np.linspace(0, 1, 6)\n",
    "bin_ranges = [bins[i-1: i+1] for i in range (1,len(bins))]\n",
    "bin_ranges =  np.array(bin_ranges)\n",
    "\n",
    "# y = y_test[:,1]\n",
    "# subs = np.abs(y-predict)\n",
    "# print(\"ave, std, per90:\", np.average(subs), \", \", np.std(subs), \",\", np.percentile(subs, 60))\n",
    "    \n",
    "for r in bin_ranges:\n",
    "    # Get valance\n",
    "    y = y_test[:,1]\n",
    "    condition1 = [r[0] <= e <= r[1]for e in y]\n",
    "    \n",
    "    predict = predict.flatten()\n",
    "    condition2 = [r[0] <= e <= r[1]for e in predict]\n",
    "    \n",
    "    y = y[condition1 or condition2]\n",
    "    pre = predict[condition1 or condition2]\n",
    "    #pre= pre.flatten()\n",
    "    #print(pre)\n",
    "    subs = np.abs(y-pre)\n",
    "   # print(subs)\n",
    "    try:\n",
    "        #print(subs)\n",
    "        print(\"\\nIn range \" , r, \n",
    "              \"\\nNum samples: \", len(subs),\n",
    "              \"\\nAverage err: \", np.average(subs), \n",
    "              \"\\nStd err: \", np.std(subs),\n",
    "              \"\\nMedian err: \", np.median(subs), \n",
    "             \"\\nPercentile: \", np.percentile(subs, 90),\n",
    "              \"\\nConfident Interval: \", mean_confidence_interval(subs)\n",
    "             )\n",
    "    except:\n",
    "        print(\"null array\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.99):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "predict = clf2.predict(X_test)\n",
    "bins = np.linspace(0, 6, 7)\n",
    "bin_ranges = [bins[i-1: i+1] for i in range (1,len(bins))]\n",
    "bin_ranges =  np.array(bin_ranges)\n",
    "\n",
    "\n",
    "for r in bin_ranges:\n",
    "    # Get valance\n",
    "    y = y_test[:,1]\n",
    "    condition1 = [r[0] <= e <= r[1]for e in y]\n",
    "    \n",
    "    predict = predict.flatten()\n",
    "    condition2 = [r[0] <= e <= r[1]for e in predict]\n",
    "    \n",
    "    y = y[condition1 or condition2]\n",
    "    pre = predict[condition1 or condition2]\n",
    "    #pre= pre.flatten()\n",
    "    print(pre)\n",
    "    subs = np.abs(y-pre)\n",
    "   # print(subs)\n",
    "    try:\n",
    "        print(subs)\n",
    "        print(\"\\nIn range \" , r, \n",
    "              \"\\nNum samples: \", len(subs),\n",
    "              \"\\nAverage err: \", np.average(subs), \n",
    "              \"\\nStd err: \", np.std(subs),\n",
    "              \"\\nMedian err: \", np.median(subs), \n",
    "             \"\\nPercentile: \", np.percentile(subs, 95),\n",
    "              \"\\nConfident Interval: \", mean_confidence_interval(subs)\n",
    "             )\n",
    "    except:\n",
    "        print(\"null array\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "predict = np.array([p[0] for p in predict])\n",
    "\n",
    "predict1 = model1.predict(X_test)\n",
    "predict1 = np.array([p[0] for p in predict1])\n",
    "\n",
    "predict2 = model2.predict(X_test)\n",
    "predict2 = np.array([p[0] for p in predict2])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test[:,1], predict1, edgecolors=(0, 0, 0))\n",
    "#ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "\n",
    "# ax[1].scatter(y_test[:,1], predict, edgecolors=(0, 0, 0))\n",
    "# ax[1].plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "# ax[1].set_xlabel('Actual')\n",
    "# ax[1].set_ylabel('Predicted')\n",
    "\n",
    "# ax[2].scatter(y_test[:,2], predict, edgecolors=(0, 0, 0))\n",
    "# ax[2].plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "# ax[2].set_xlabel('Actual')\n",
    "# ax[2].set_ylabel('Predicted')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Playing around **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "predict = model2.predict(X_test)\n",
    "\n",
    "def reducer(acc, val):\n",
    "    if (val > 0.5):\n",
    "        acc = acc + 1\n",
    "    return acc\n",
    "\n",
    "num = reduce(lambda acc,val: acc+1 if val >1 else acc, predict.flatten(), 0) \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confidence in interval for Arouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf2.predict(X_test)\n",
    "print(predict)\n",
    "#predict = clf2.predict(X_test)\n",
    "#print(predict)\n",
    "#predict = np.array([p[0] for p in predict])\n",
    "y = y_test[:, 1]\n",
    "y1=y\n",
    "#y1 = np.argmax(y,1)\n",
    "cm = confusion_matrix(y1, predict)\n",
    "print(\"Confusion matrix: \\n\", cm)\n",
    "\n",
    "\n",
    "bins = np.linspace(0, 5, 6)\n",
    "bin_ranges = [bins[i-1: i+1] for i in range (1,len(bins))]\n",
    "bin_ranges =  np.array(bin_ranges)\n",
    "\n",
    "for r in bin_ranges:\n",
    "     condition = [r[0] <= e <= r[1] for e in y]\n",
    "     y1 = y[condition]\n",
    "     pre = predict.flatten()\n",
    "     pre = pre[condition]\n",
    "     num_true = 0\n",
    "     for i in range (0, len(y1)):\n",
    "        if (np.abs(y1[i] - pre[i]) ==0 ):\n",
    "            num_true += 1\n",
    "     print(\"Num samples:\", len(pre))\n",
    "     print(\"Accurcy in range: \", r, \": \", num_true / (len(pre) +1 ) )\n",
    "            \n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "y_int = y.astype(int)\n",
    "\n",
    "ax[0].hist(y)\n",
    "ax[0].set_ylim([0,650])\n",
    "ax[1].hist(y_int)\n",
    "ax[1].set_ylim([0,650])\n",
    "ax[2].hist(predict)\n",
    "ax[2].set_ylim([0,650])\n",
    "        \n",
    "print(set(predict))\n",
    "print(len(predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

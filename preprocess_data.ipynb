{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "import numpy\n",
    "import librosa\n",
    "import pickle\n",
    "import acousticFeatures\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define class\n",
    "class Input:\n",
    "    \n",
    "    def __init__(self, code=None, spectrogram=None, acoustic_features=None, transcript=None):\n",
    "        self.__code = code\n",
    "        self.__spectrogram = spectrogram\n",
    "        self.__acoustic_features = acoustic_features\n",
    "        self.__transcript = transcript\n",
    "    \n",
    "    def get_code(self):\n",
    "        return self.__code\n",
    "            \n",
    "    def get_spectrogram(self):\n",
    "        return self.__spectrogram\n",
    "    \n",
    "    def get_acoustic_features(self):\n",
    "        return self.__acoustic_features\n",
    "    \n",
    "    def get_transcript(self):\n",
    "        return self.__transcript\n",
    "    \n",
    "    def set_transcript(self, transcript):\n",
    "        self.__transcript = transcript\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Output:\n",
    "    def __init__(self, code, duration, annotated_categories, chosen_category, attributes):\n",
    "        self.__code = code # file name\n",
    "        self.__duration = duration #  duration [t1-t2]\n",
    "        self.__annotated_categories= annotated_categories # array of different category evaluation of annotator\n",
    "        self.__chosen_category = chosen_category  # final category which most of annotators choose\n",
    "        self.__attributes = attributes # valance, arouse, dominance of emotion\n",
    "        \n",
    "    \n",
    "    def get_code(self):\n",
    "        return self.__code\n",
    "\n",
    "    def get_duration(self):\n",
    "        return self.__duration\n",
    "    \n",
    "    def get_annotated_categories(self):\n",
    "        return self.__annotated_categories\n",
    "    \n",
    "    def get_chosen_category(self):\n",
    "        return self.__chosen_category\n",
    "    \n",
    "    def get_attributes(self):\n",
    "        return self.__attributes\n",
    "        \n",
    "        \n",
    "    def get_consitency(self):\n",
    "        \"\"\"Check if most of annotators have the same evaluation.\n",
    "        \"\"\"\n",
    "        counts = np.unique(self.get_annotated_categories(), return_counts=True)[1]\n",
    "        consitent_degree = np.max(counts)/np.sum(counts)\n",
    "        return consitent_degree\n",
    "            \n",
    "    \n",
    "\n",
    "        \n",
    "#Function for getting input vector and corresponding output      \n",
    "def parallel_task(d0, d1, d2):\n",
    "    print(\"task...\")\n",
    "    \n",
    "    def get_transcription(file: str) -> Dict[str, str] :\n",
    "        \"\"\" Get all transriptions in file\n",
    "\n",
    "            :param file: It is the name(code) of the file\n",
    "            :return: Dict. Keys are name of audio files. Values are their transcrips\n",
    "        \"\"\"\n",
    "        dicts = {} # Dict containing the result \n",
    "        with open(file) as f:\n",
    "            for line in f:\n",
    "                parts = line.split(' ', maxsplit=2) # Example of one line in file: Name_file [t1-t2]: Transcript.\n",
    "                try:\n",
    "                    dicts[parts[0]] = parts[2]\n",
    "                except:\n",
    "                    print(\"Error caused by: \", parts)\n",
    "                    print(\"In file:\", file)\n",
    "                    dicts[parts[0]] = \"\"\n",
    "\n",
    "        return dicts\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parseInput(dir):\n",
    "        \"\"\"Each input diectory contains many file\n",
    "           This fucntion will walk through all valid 'wav'files in this directory and get features like spectrogram, acoustic\n",
    "           Transcript will insert into input later.\n",
    "        \"\"\"\n",
    "        \n",
    "        dicts = {} \n",
    "        for f in os.listdir(dir):\n",
    "            if not f.startswith(\".\") and os.path.splitext(f)[1] == \".wav\":\n",
    "                # Get file name\n",
    "                code = os.path.splitext(f)[0] \n",
    "                \n",
    "                # Get file path\n",
    "                file_path = \"/\".join([dir, code]) + \".wav\"\n",
    "                \n",
    "                # Create histogram\n",
    "                y, sr = librosa.load(file_path)\n",
    "                spectrogram = librosa.stft(y)\n",
    "                spectrogram = np.abs(spectrogram)\n",
    "                \n",
    "                # Create acoustic features\n",
    "                acoustic_features = acousticFeatures.getAllFeatures(file_path)\n",
    "                \n",
    "                dicts[code] = Input(code, spectrogram, acoustic_features, transcript=None)\n",
    "\n",
    "        return dicts\n",
    "    \n",
    "    \n",
    "    def parseOutput(file):\n",
    "        \"\"\"Each output file contains label of many diffrent 'wav' file.\n",
    "           This function will parse content of text file using 'regrex'. Then turn it into label\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        dict_namefile_output = {}\n",
    "        \n",
    "        # Open file to get all contents excepts the first line.\n",
    "        f = open(file, 'r')\n",
    "        content = \"\"\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            index = index + 1\n",
    "            if index == 1:\n",
    "                continue\n",
    "            content  = content + line\n",
    "\n",
    "        # Find all matched patterns in the content\n",
    "        ps = re.findall(r'\\[.*?\\)\\n\\n', content, re.DOTALL)\n",
    "\n",
    "        # Parse each matched pattern into  'Output' object\n",
    "        try:\n",
    "            for p in ps:\n",
    "                ls = p.split(\"\\n\")\n",
    "                ls = list(filter(lambda x: len(x) > 0 ,ls))\n",
    "\n",
    "                # Split elements of the first line which looks like : \n",
    "                # [147.0300 - 151.7101]\tSes01F_impro02_M012\tneu\t[2.5000, 2.0000, 2.0000]\n",
    "                ele_line0 = re.search(r'(\\[.*?\\])(\\s)(.*?)(\\s)(.*?)(\\s)(\\[.*?\\])', ls[0]).groups()\n",
    "\n",
    "                # Split time components which looks like:\n",
    "                # [147.0300 - 151.7101]\n",
    "                time_dur = ele_line0[0]\n",
    "                ele_time_dur = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", time_dur)\n",
    "                ele_time_dur = [float(x) for x in ele_time_dur]\n",
    "\n",
    "                # Get code and category_origin which looks like:\n",
    "                # Code: Ses01F_impro02_M012\n",
    "                # Category_origin: neu\n",
    "                code = ele_line0[2]\n",
    "                chosen_category = ele_line0[4]\n",
    "\n",
    "                # Split attribute components which looks like:\n",
    "                # [2.5000, 2.0000, 2.0000]\n",
    "                attribute = ele_line0[6]\n",
    "                ele_attribute = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", attribute)\n",
    "                ele_attribute = [float(x) for x in ele_attribute]\n",
    "\n",
    "                # Get categorial_evaluation:\n",
    "                lines_categorical = list(filter(lambda x : x[0] == 'C', ls))\n",
    "                rex = re.compile(r'C.*?:(\\s)(.*?)(\\s)\\(.*?\\)')\n",
    "\n",
    "                annotated_categories = []\n",
    "                for l in lines_categorical:\n",
    "                    elements = rex.search(l).groups()\n",
    "                    cat = elements[1]\n",
    "                    cat = cat.split(\";\")\n",
    "                    cat = map(lambda x: x.lstrip(), cat)\n",
    "                    cat = list(filter(lambda x: len(x)>0, cat))\n",
    "                    annotated_categories.extend(cat)\n",
    "\n",
    "\n",
    "                annotated_categories = np.array(annotated_categories)\n",
    "                                \n",
    "                \n",
    "\n",
    "                # Make dict {name_file : parsed_output}\n",
    "                dict_namefile_output[code] = Output(code, ele_time_dur, annotated_categories, chosen_category, ele_attribute)\n",
    "            return dict_namefile_output\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    ### Parse input and output files and get input and output as vector\n",
    "    dicts_in = parseInput(d0)\n",
    "    dicts_out = parseOutput(d1)\n",
    "    dicts_transcript = get_transcription(d2)\n",
    "    in_out = []\n",
    "    \n",
    "    keys = list(dicts_in.keys())\n",
    "    for key in keys:\n",
    "        # Insert transcript into Input object\n",
    "        dicts_in[key].set_transcript(dicts_transcript[key])\n",
    "        \n",
    "        # Make a tuple (Input, Output)\n",
    "        in_out.append((dicts_in[key], dicts_out[key]))\n",
    "            \n",
    "    return in_out\n",
    "    \n",
    "    \n",
    "def createInput_Output():\n",
    "    ### Get directories of input and output\n",
    "    DATA_DIR = \"auditary_emotion_recognition/IEMOCAP_full_release\"\n",
    "    NUM_SESSION = 5\n",
    "    input_output = []\n",
    "    for i in range (1, NUM_SESSION + 1):\n",
    "        name_session = \"Session\" + str(i)\n",
    "        root_dir_of_wav = DATA_DIR + \"/\" + name_session + \"/sentences\" + \"/wav\"\n",
    "        root_dir_of_labels = DATA_DIR + \"/\" + name_session + \"/dialog\" + \"/EmoEvaluation\"\n",
    "        root_dir_of_transcripts = DATA_DIR + \"/\" + name_session + \"/dialog\" + \"/transcriptions\"\n",
    "\n",
    "        for x in os.walk(root_dir_of_wav):\n",
    "            if(x[0] == root_dir_of_wav):\n",
    "                dirs_of_wav = x[1]\n",
    "                index = -1\n",
    "            else:\n",
    "                index = index + 1\n",
    "                input_output.append((x[0], \n",
    "                                     root_dir_of_labels + \"/\" + dirs_of_wav[index] + \".txt\",\n",
    "                                     root_dir_of_transcripts + \"/\" + dirs_of_wav[index] + \".txt\"\n",
    "                                   ))\n",
    "                \n",
    "    \n",
    "    ds = input_output\n",
    "    in_out = []\n",
    "    \n",
    "    # Multi processing\n",
    "    with Pool(processes=30) as pool:\n",
    "         in_out = pool.starmap(parallel_task, ds)\n",
    "    \n",
    "    # Append all the result which returned by multi proccessing.\n",
    "    r = []\n",
    "    for e in in_out:\n",
    "        r = r + e\n",
    "    \n",
    "    input = [x[0] for x in r]\n",
    "    out = [x[1] for x in r]\n",
    "    print(\"Finished creating input output into txt file\")\n",
    "    print(\"len input and output:\", len(input), \", \", len(out))\n",
    "    \n",
    "    return (input, out)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create input, output \n",
    "input, output = createInput_Output()\n",
    "input = np.array(input)\n",
    "output = np.array(output)\n",
    "  \n",
    "# Define file handler\n",
    "filehandlerInput = open('processed-data/input.obj', 'wb')\n",
    "filehandlerOutput = open('processed-data/output.obj', 'wb')\n",
    "\n",
    "# Dump to files\n",
    "pickle.dump(input, filehandlerInput)\n",
    "pickle.dump(output, filehandlerOutput)\n",
    "print(\"Finish write processed data (input, output) to file!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandlerInput = open('processed-data/input.obj', 'rb')\n",
    "filehandlerOutput = open('processed-data/output.obj', 'rb')\n",
    "\n",
    "# Dump to files\n",
    "x = pickle.load(filehandlerInput)\n",
    "y = pickle.load( filehandlerOutput)\n",
    "\n",
    "for i in y:\n",
    "    print(\"category: {}, VAD: {}, consitent: {}\".format(i.get_chosen_category(), i.get_attributes(), i.isConsitent()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
